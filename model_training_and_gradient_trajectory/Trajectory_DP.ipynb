{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE='cuda:0'\n",
    "DIMENSION=224\n",
    "MINI_BS=100\n",
    "BS=1000\n",
    "LR=1e-4\n",
    "MODEL='vit_base_patch16_224'\n",
    "#MODEL_PATH='./checkpoints/nonDP_model_epoch_2.pth'\n",
    "MODEL_PATH='./checkpoints/DP_model_begin.pth'\n",
    "EPOCHS=10\n",
    "\n",
    "n_acc_steps = BS // MINI_BS # gradient accumulation steps\n",
    "\n",
    "EPSILON=2\n",
    "DELTA=1e-5\n",
    "CLIPPING_STYLE='all-layer'\n",
    "CLIPPING_MODE='MixOpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device= torch.device(DEVICE if torch.cuda.is_available() else \"cpu\") #默认为cuda:0\n",
    "print(\"device:\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "print('==> Preparing data..')\n",
    "\n",
    "import torchvision\n",
    "transformation = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(DIMENSION),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='data/', train=True, download=True, transform=transformation)\n",
    "testset = torchvision.datasets.CIFAR100(root='data/', train=False, download=True, transform=transformation)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=MINI_BS, shuffle=True, num_workers=4) # shuffle会在数据加载前打乱数据集\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model.. vit_base_patch16_224 ; BatchNorm is replaced by GroupNorm. Mode:  MixOpt\n",
      "Number of total parameters:  85875556\n",
      "Number of trainable parameters:  85875556\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from opacus.validators import ModuleValidator\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "checkpoint = torch.load(MODEL_PATH)\n",
    "\n",
    "num_classes=100\n",
    "print('==> Building model..', MODEL,'; BatchNorm is replaced by GroupNorm. Mode: ', CLIPPING_MODE)\n",
    "net = timm.create_model(MODEL,pretrained=True,num_classes=num_classes)\n",
    "net = ModuleValidator.fix(net); # fix使其能用于DP训练\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "net=net.to(device) \n",
    "\n",
    "print('Number of total parameters: ', sum([p.numel() for p in net.parameters()]))\n",
    "print('Number of trainable parameters: ', sum([p.numel() for p in net.parameters() if p.requires_grad]))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/musheng/miniconda3/envs/DP/lib/python3.9/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using origin parameters for the ghost differentiation trick......\n",
      "Number of trainable components:  150 ; Number of trainable layers:  75\n",
      ">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",
      ">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['patch_embed.proj']\n"
     ]
    }
   ],
   "source": [
    "from opacus.accountants.utils import get_noise_multiplier\n",
    "sigma=get_noise_multiplier( # Computes the noise level sigma to reach a total budget of (target_epsilon, target_delta) at the end of epochs, with a given sample_rate\n",
    "                target_epsilon = EPSILON,\n",
    "                target_delta = DELTA,\n",
    "                sample_rate = BS/len(trainset),\n",
    "                epochs = EPOCHS,\n",
    ")\n",
    "\n",
    "from fastDP import PrivacyEngine\n",
    "privacy_engine = PrivacyEngine(\n",
    "    net,\n",
    "    batch_size=BS,\n",
    "    sample_size=len(trainset),\n",
    "    noise_multiplier=sigma,\n",
    "    max_grad_norm=1,\n",
    "    epochs=EPOCHS,\n",
    "    clipping_mode=CLIPPING_MODE,\n",
    "    clipping_style=CLIPPING_STYLE,\n",
    "    origin_params=['patch_embed.proj.bias'],#['patch_embed.proj.bias'],\n",
    ")\n",
    "privacy_engine.attach(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./DP_checkpoints/begin_0.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb4a7cbe5e74c09a2beef73457c5c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/musheng/miniconda3/envs/DP/lib/python3.9/site-packages/torch/nn/modules/module.py:1033: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "1\n",
      "Model saved to ./DP_checkpoints/begin_1.pth\n",
      "768\n",
      "2\n",
      "Model saved to ./DP_checkpoints/begin_2.pth\n",
      "768\n",
      "3\n",
      "Model saved to ./DP_checkpoints/begin_3.pth\n",
      "768\n",
      "4\n",
      "Model saved to ./DP_checkpoints/begin_4.pth\n",
      "768\n",
      "5\n",
      "Model saved to ./DP_checkpoints/begin_5.pth\n",
      "768\n",
      "6\n",
      "Model saved to ./DP_checkpoints/begin_6.pth\n",
      "768\n",
      "7\n",
      "Model saved to ./DP_checkpoints/begin_7.pth\n",
      "768\n",
      "8\n",
      "Model saved to ./DP_checkpoints/begin_8.pth\n",
      "768\n",
      "9\n",
      "Model saved to ./DP_checkpoints/begin_9.pth\n",
      "768\n",
      "10\n",
      "Model saved to ./DP_checkpoints/begin_10.pth\n",
      "----------------------------------------------------------------------------------------\n",
      "Epoch: none, step: 100, Train Loss: 4.256 | Acc: 10.710% (1071/10000)\n",
      "768\n",
      "11\n",
      "Model saved to ./DP_checkpoints/begin_11.pth\n",
      "768\n",
      "12\n",
      "Model saved to ./DP_checkpoints/begin_12.pth\n",
      "768\n",
      "13\n",
      "Model saved to ./DP_checkpoints/begin_13.pth\n",
      "768\n",
      "14\n",
      "Model saved to ./DP_checkpoints/begin_14.pth\n",
      "768\n",
      "15\n",
      "Model saved to ./DP_checkpoints/begin_15.pth\n",
      "768\n",
      "16\n",
      "Model saved to ./DP_checkpoints/begin_16.pth\n",
      "768\n",
      "17\n",
      "Model saved to ./DP_checkpoints/begin_17.pth\n",
      "768\n",
      "18\n",
      "Model saved to ./DP_checkpoints/begin_18.pth\n",
      "768\n",
      "19\n",
      "Model saved to ./DP_checkpoints/begin_19.pth\n",
      "768\n",
      "20\n",
      "Model saved to ./DP_checkpoints/begin_20.pth\n",
      "----------------------------------------------------------------------------------------\n",
      "Epoch: none, step: 200, Train Loss: 4.103 | Acc: 14.400% (2880/20000)\n",
      "768\n",
      "21\n",
      "Model saved to ./DP_checkpoints/begin_21.pth\n",
      "768\n",
      "22\n",
      "Model saved to ./DP_checkpoints/begin_22.pth\n",
      "768\n",
      "23\n",
      "Model saved to ./DP_checkpoints/begin_23.pth\n",
      "768\n",
      "24\n",
      "Model saved to ./DP_checkpoints/begin_24.pth\n",
      "768\n",
      "25\n",
      "Model saved to ./DP_checkpoints/begin_25.pth\n",
      "768\n",
      "26\n",
      "Model saved to ./DP_checkpoints/begin_26.pth\n",
      "768\n",
      "27\n",
      "Model saved to ./DP_checkpoints/begin_27.pth\n",
      "768\n",
      "28\n",
      "Model saved to ./DP_checkpoints/begin_28.pth\n",
      "768\n",
      "29\n",
      "Model saved to ./DP_checkpoints/begin_29.pth\n",
      "768\n",
      "30\n",
      "Model saved to ./DP_checkpoints/begin_30.pth\n",
      "----------------------------------------------------------------------------------------\n",
      "Epoch: none, step: 300, Train Loss: 3.937 | Acc: 17.887% (5366/30000)\n",
      "768\n",
      "31\n",
      "Model saved to ./DP_checkpoints/begin_31.pth\n",
      "768\n",
      "32\n",
      "Model saved to ./DP_checkpoints/begin_32.pth\n",
      "768\n",
      "33\n",
      "Model saved to ./DP_checkpoints/begin_33.pth\n",
      "768\n",
      "34\n",
      "Model saved to ./DP_checkpoints/begin_34.pth\n",
      "768\n",
      "35\n",
      "Model saved to ./DP_checkpoints/begin_35.pth\n",
      "768\n",
      "36\n",
      "Model saved to ./DP_checkpoints/begin_36.pth\n",
      "768\n",
      "37\n",
      "Model saved to ./DP_checkpoints/begin_37.pth\n",
      "768\n",
      "38\n",
      "Model saved to ./DP_checkpoints/begin_38.pth\n",
      "768\n",
      "39\n",
      "Model saved to ./DP_checkpoints/begin_39.pth\n",
      "768\n",
      "40\n",
      "Model saved to ./DP_checkpoints/begin_40.pth\n",
      "----------------------------------------------------------------------------------------\n",
      "Epoch: none, step: 400, Train Loss: 3.769 | Acc: 21.175% (8470/40000)\n",
      "768\n",
      "41\n",
      "Model saved to ./DP_checkpoints/begin_41.pth\n",
      "768\n",
      "42\n",
      "Model saved to ./DP_checkpoints/begin_42.pth\n",
      "768\n",
      "43\n",
      "Model saved to ./DP_checkpoints/begin_43.pth\n",
      "768\n",
      "44\n",
      "Model saved to ./DP_checkpoints/begin_44.pth\n",
      "768\n",
      "45\n",
      "Model saved to ./DP_checkpoints/begin_45.pth\n",
      "768\n",
      "46\n",
      "Model saved to ./DP_checkpoints/begin_46.pth\n",
      "768\n",
      "47\n",
      "Model saved to ./DP_checkpoints/begin_47.pth\n",
      "768\n",
      "48\n",
      "Model saved to ./DP_checkpoints/begin_48.pth\n",
      "768\n",
      "49\n",
      "Model saved to ./DP_checkpoints/begin_49.pth\n",
      "768\n",
      "50\n",
      "Model saved to ./DP_checkpoints/begin_50.pth\n",
      "----------------------------------------------------------------------------------------\n",
      "Epoch: none, step: 500, Train Loss: 3.602 | Acc: 24.398% (12199/50000)\n",
      "Epoch:  none total:  500 Train Loss: 3.602 | Acc: 24.398% (12199/50000)\n"
     ]
    }
   ],
   "source": [
    "#先进行训练，存储模型并得到true_gradient\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "SHOW_STEPS=100\n",
    "\n",
    "STAGE='begin'\n",
    "NUM=0\n",
    "model_path = f'./DP_checkpoints/{STAGE}_{NUM}.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': net.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, model_path)\n",
    "print(f'Model saved to {model_path}')\n",
    "\n",
    "#特别注意！在这里只有patch_embed.proj.bias层有反向传播机制(768维的grad向量)\n",
    "\n",
    "# def get_gradient(net):\n",
    "#     current_gradient = []\n",
    "#     for param in net.parameters():\n",
    "#         current_gradient.append(param.grad.view(-1).detach().cpu().numpy())\n",
    "#     # print(len(current_gradient))\n",
    "#     # print([i.size for i in current_gradient])\n",
    "#     gradient=np.concatenate(current_gradient)\n",
    "#     return gradient\n",
    "\n",
    "def get_gradient(net):\n",
    "    current_gradient = []\n",
    "    for name, param in net.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            if name=='patch_embed.proj.bias':\n",
    "                #print(f\"Parameter: {name}, Gradient: {param.grad}\")\n",
    "                current_gradient.append(param.grad.view(-1).detach().cpu().numpy())\n",
    "    gradient=np.concatenate(current_gradient)\n",
    "    #print(gradient.size)\n",
    "    return gradient\n",
    "\n",
    "\n",
    "true_gradient=[]\n",
    "\n",
    "net.train()\n",
    "train_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "\n",
    "for batch_idx, (inputs, targets) in enumerate(tqdm(trainloader)): #这里的batch_idx应该相当于step？\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, targets) # 交叉熵函数作为LossFunction\n",
    "    loss.backward()\n",
    "    #print(loss)\n",
    "    # 每个mini_batch都有自己的一个true gradient\n",
    "    if ((batch_idx + 1) % n_acc_steps == 0) or ((batch_idx + 1) == len(trainloader)):\n",
    "        present_true_gradient=get_gradient(net)\n",
    "        true_gradient.append(present_true_gradient)\n",
    "        print(len(true_gradient))\n",
    "        optimizer.step() # 每积累n_acc_steps步的梯度后进行一次更新参数(每执行logical batch后更新一次)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #保存每个batch_size训练后的模型\n",
    "        NUM=(batch_idx + 1) // n_acc_steps\n",
    "        model_path = f'./DP_checkpoints/{STAGE}_{NUM}.pth'\n",
    "        torch.save({\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, model_path)\n",
    "        print(f'Model saved to {model_path}')\n",
    "        \n",
    "        \n",
    "    train_loss += loss.item()\n",
    "    _, predicted = outputs.max(1)\n",
    "    total += targets.size(0)\n",
    "    correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "\n",
    "\n",
    "    # print log\n",
    "    if ((batch_idx + 1) % SHOW_STEPS == 0) or ((batch_idx + 1) == len(trainloader)):\n",
    "        #privacy_spent = privacy_engine.get_privacy_spent(accounting_mode=\"all\", lenient=False)\n",
    "        tqdm.write(\"----------------------------------------------------------------------------------------\")\n",
    "        tqdm.write('Epoch: {}, step: {}, Train Loss: {:.3f} | Acc: {:.3f}% ({}/{})'.format(\n",
    "            'none', batch_idx + 1, train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "        #tqdm.write(\"Privacy Cost: ε_rdp: {:.3f} | α_rdp: {:.1f} | ε_low: {:.3f} | ε_estimate: {:.3f} | ε_upper: {:.3f}\".format(\n",
    "            #privacy_spent[\"eps_rdp\"], privacy_spent[\"alpha_rdp\"], privacy_spent[\"eps_low\"], privacy_spent[\"eps_estimate\"], privacy_spent[\"eps_upper\"]))\n",
    "\n",
    "np.save(f'./gradients/DP_{STAGE}_true_gradients.npy', true_gradient)\n",
    "\n",
    "\n",
    "print('Epoch: ', 'none', \"total: \", len(trainloader), 'Train Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                    % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对每个true gradient分别计算相应的per-sample gradient\n",
    "MINI_BS=1\n",
    "BS=1\n",
    "n_acc_steps = BS // MINI_BS # gradient accumulation steps\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=MINI_BS, shuffle=True, num_workers=4) # shuffle会在数据加载前打乱数据集\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n",
      "==> Building model.. vit_base_patch16_224 ; BatchNorm is replaced by GroupNorm. Mode:  MixOpt\n",
      "Number of total parameters:  85875556\n",
      "Number of trainable parameters:  85875556\n",
      "Using origin parameters for the ghost differentiation trick......\n",
      "Number of trainable components:  150 ; Number of trainable layers:  75\n",
      ">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",
      ">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['patch_embed.proj']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/musheng/miniconda3/envs/DP/lib/python3.9/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ae9ef982e841a09e86ae1aee38960a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cls_token', 'pos_embed'] are not supported by privacy engine; these parameters are not requiring gradient nor updated.\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "20\n",
      "i= 1\n",
      "==> Building model.. vit_base_patch16_224 ; BatchNorm is replaced by GroupNorm. Mode:  MixOpt\n",
      "Number of total parameters:  85875556\n",
      "Number of trainable parameters:  85875556\n",
      "Using origin parameters for the ghost differentiation trick......\n",
      "Number of trainable components:  150 ; Number of trainable layers:  75\n",
      ">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",
      ">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['patch_embed.proj']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0b8cd479144cd09088011cf08dc023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cls_token', 'pos_embed'] are not supported by privacy engine; these parameters are not requiring gradient nor updated.\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "20\n",
      "i= 2\n",
      "==> Building model.. vit_base_patch16_224 ; BatchNorm is replaced by GroupNorm. Mode:  MixOpt\n",
      "Number of total parameters:  85875556\n",
      "Number of trainable parameters:  85875556\n",
      "Using origin parameters for the ghost differentiation trick......\n",
      "Number of trainable components:  150 ; Number of trainable layers:  75\n",
      ">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",
      ">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['patch_embed.proj']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7c042af8b349638ec8e107b6363f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cls_token', 'pos_embed'] are not supported by privacy engine; these parameters are not requiring gradient nor updated.\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "20\n",
      "i= 3\n",
      "==> Building model.. vit_base_patch16_224 ; BatchNorm is replaced by GroupNorm. Mode:  MixOpt\n",
      "Number of total parameters:  85875556\n",
      "Number of trainable parameters:  85875556\n",
      "Using origin parameters for the ghost differentiation trick......\n",
      "Number of trainable components:  150 ; Number of trainable layers:  75\n",
      ">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",
      ">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['patch_embed.proj']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0fc9a589aa4e63b1ba82c44f30618c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cls_token', 'pos_embed'] are not supported by privacy engine; these parameters are not requiring gradient nor updated.\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "20\n",
      "i= 4\n",
      "==> Building model.. vit_base_patch16_224 ; BatchNorm is replaced by GroupNorm. Mode:  MixOpt\n",
      "Number of total parameters:  85875556\n",
      "Number of trainable parameters:  85875556\n",
      "Using origin parameters for the ghost differentiation trick......\n",
      "Number of trainable components:  150 ; Number of trainable layers:  75\n",
      ">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",
      ">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['patch_embed.proj']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87185f64e3b847ed8240371c6840809e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cls_token', 'pos_embed'] are not supported by privacy engine; these parameters are not requiring gradient nor updated.\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "20\n",
      "i= 5\n",
      "==> Building model.. vit_base_patch16_224 ; BatchNorm is replaced by GroupNorm. Mode:  MixOpt\n",
      "Number of total parameters:  85875556\n",
      "Number of trainable parameters:  85875556\n",
      "Using origin parameters for the ghost differentiation trick......\n",
      "Number of trainable components:  150 ; Number of trainable layers:  75\n",
      ">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",
      ">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['patch_embed.proj']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fcd88cd19143cb8d7950816588ebf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cls_token', 'pos_embed'] are not supported by privacy engine; these parameters are not requiring gradient nor updated.\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "20\n",
      "i= 6\n",
      "==> Building model.. vit_base_patch16_224 ; BatchNorm is replaced by GroupNorm. Mode:  MixOpt\n",
      "Number of total parameters:  85875556\n",
      "Number of trainable parameters:  85875556\n",
      "Using origin parameters for the ghost differentiation trick......\n",
      "Number of trainable components:  150 ; Number of trainable layers:  75\n",
      ">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",
      ">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['patch_embed.proj']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187f4f981358410190559ad8ae3064b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cls_token', 'pos_embed'] are not supported by privacy engine; these parameters are not requiring gradient nor updated.\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "20\n",
      "i= 7\n",
      "==> Building model.. vit_base_patch16_224 ; BatchNorm is replaced by GroupNorm. Mode:  MixOpt\n",
      "Number of total parameters:  85875556\n",
      "Number of trainable parameters:  85875556\n",
      "Using origin parameters for the ghost differentiation trick......\n",
      "Number of trainable components:  150 ; Number of trainable layers:  75\n",
      ">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",
      ">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['patch_embed.proj']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600ba62adc9f431e912186e40fefc532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cls_token', 'pos_embed'] are not supported by privacy engine; these parameters are not requiring gradient nor updated.\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m outputs \u001b[38;5;241m=\u001b[39m net(inputs)\n\u001b[1;32m     59\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets) \u001b[38;5;66;03m# 交叉熵函数作为LossFunction\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m((batch_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m50\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     63\u001b[0m     present_per_sample_gradient\u001b[38;5;241m=\u001b[39mget_gradient(net)\n",
      "File \u001b[0;32m/data/musheng/miniconda3/envs/DP/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/musheng/miniconda3/envs/DP/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from opacus.validators import ModuleValidator\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "total_per_sample_gradient=[]\n",
    "\n",
    "for i in range(50):\n",
    "    print('i=',i)\n",
    "    MODEL_PATH='DP_checkpoints/'+STAGE+\"_\"+str(i)+'.pth'\n",
    "    checkpoint = torch.load(MODEL_PATH)\n",
    "    num_classes=100\n",
    "    print('==> Building model..', MODEL,'; BatchNorm is replaced by GroupNorm. Mode: ', CLIPPING_MODE)\n",
    "    net = timm.create_model(MODEL,pretrained=True,num_classes=num_classes)\n",
    "    net = ModuleValidator.fix(net); # fix使其能用于DP训练\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    net=net.to(device) \n",
    "\n",
    "    print('Number of total parameters: ', sum([p.numel() for p in net.parameters()]))\n",
    "    print('Number of trainable parameters: ', sum([p.numel() for p in net.parameters() if p.requires_grad]))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=LR)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    from opacus.accountants.utils import get_noise_multiplier\n",
    "    sigma=get_noise_multiplier( # Computes the noise level sigma to reach a total budget of (target_epsilon, target_delta) at the end of epochs, with a given sample_rate\n",
    "                    target_epsilon = EPSILON,\n",
    "                    target_delta = DELTA,\n",
    "                    sample_rate = BS/len(trainset),\n",
    "                    epochs = EPOCHS,\n",
    "    )\n",
    "    from fastDP import PrivacyEngine\n",
    "    privacy_engine = PrivacyEngine(\n",
    "        net,\n",
    "        batch_size=BS,\n",
    "        sample_size=len(trainset),\n",
    "        noise_multiplier=sigma,\n",
    "        max_grad_norm=1,\n",
    "        epochs=EPOCHS,\n",
    "        clipping_mode=CLIPPING_MODE,\n",
    "        clipping_style=CLIPPING_STYLE,\n",
    "        origin_params=['patch_embed.proj.bias'],#['patch_embed.proj.bias'],\n",
    "    )\n",
    "    privacy_engine.attach(optimizer)\n",
    "\n",
    "\n",
    "    i_per_sample_gradient=[]\n",
    "\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(trainloader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets) # 交叉熵函数作为LossFunction\n",
    "        loss.backward()\n",
    "\n",
    "        if((batch_idx+1)%50==0):\n",
    "            present_per_sample_gradient=get_gradient(net)\n",
    "            i_per_sample_gradient.append(present_per_sample_gradient)\n",
    "        \n",
    "        optimizer.step() # 每积累n_acc_steps步的梯度后进行一次更新参数(每执行logical batch后更新一次)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "\n",
    "        if(batch_idx+1==1000):\n",
    "            break\n",
    "    print(len(i_per_sample_gradient))\n",
    "    np.save(f'./gradients/DP_{STAGE}_{i}_gradients.npy', i_per_sample_gradient)\n",
    "    #total_per_sample_gradient.append(i_per_sample_gradient)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
